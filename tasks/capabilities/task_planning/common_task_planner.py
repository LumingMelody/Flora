import logging
import json
import re
import networkx as nx  # éœ€è¦å¼•å…¥ networkx
from typing import List, Dict, Optional, Any, Tuple
from .interface import ITaskPlanningCapability
from external.repositories.agent_structure_repo import AgentStructureRepository 

import logging
logger = logging.getLogger(__name__)

# å‡è®¾çš„å¤–éƒ¨ä¾èµ–ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·æ›¿æ¢ä¸ºçœŸå®è·¯å¾„
# from repositories.structure import AgentStructureRepository 


##TODO:SCCçš„èŠ‚ç‚¹è¿˜æœ‰ä¸€äº›é—®é¢˜ï¼ŒåŒ…æ‹¬seqé¢„è®¾é¡ºåº
class CommonTaskPlanning(ITaskPlanningCapability):
    """
    ä»»åŠ¡è§„åˆ’å™¨ V2ï¼š
    1. è¯­ä¹‰å±‚ï¼šåŸºäº LLM å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€æ‹†è§£ä¸ºåˆæ­¥æ„å›¾é“¾ (Agent vs MCP)ã€‚
    2. ç»“æ„å±‚ï¼šåŸºäº Neo4j çŸ¥è¯†å›¾è°±ï¼Œå‘ç°éšæ€§ä¾èµ–ï¼ˆSCCï¼‰ï¼Œå¯¹ Agent ä»»åŠ¡è¿›è¡ŒååŒè§„åˆ’ä¸æ‰©å……ã€‚
    """

    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger(__name__)
        self.tree_manager = None
        self._llm = None
        self._structure_repo = None # ç”¨äºè¿æ¥ Neo4j

    def get_capability_type(self) -> str:
        return 'common_task_planning'

    def initialize(self, config: Dict[str, Any]) -> bool:
 
        from agents.tree.tree_manager import treeManager

        self.tree_manager = treeManager
        from ..llm.interface import ILLMCapability
        from ..registry import capability_registry
        self._llm = capability_registry.get_capability("llm", ILLMCapability)

        self._structure_repo = AgentStructureRepository()
        return True

    def generate_execution_plan(
        self,
        agent_id: str,
        user_input: str,
        memory_context: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        [ä¸»å…¥å£] ç”Ÿæˆå®Œæ•´çš„æ‰§è¡Œè§„åˆ’é“¾ï¼ˆè¯­ä¹‰æ‹†è§£ -> ä¾èµ–æ‰©å……ï¼‰
        """
        try:
            # Phase 1: è¯­ä¹‰æ‹†è§£ï¼ˆæ³¨å…¥è®°å¿†ï¼‰
            # è®°å¿†åœ¨è¿™é‡Œå½±å“ï¼šAgent vs MCP çš„é€‰æ‹©ï¼Œä»¥åŠç¬¬ä¸€å±‚å‚æ•°çš„æå–
            base_plan = self._semantic_decomposition(agent_id, user_input, memory_context)
            if not base_plan:
                return [
                    {
                        "step": 1,
                        "type": "MCP",
                        "executor": "mcp_llm",
                        "content": user_input,
                        "description": "auto_fallback",
                    }
                ]

            # Phase 2: ç»“æ„åŒ–æ‰©å……ï¼ˆé€ä¼ è®°å¿†ï¼‰
            # å°† memory_context æ‰“åŒ…è¿› contextï¼Œä¼ é€’ç»™ Neo4j ååŒè§„åˆ’å±‚
            expansion_context = {
                "main_intent": user_input,
                "global_memory": memory_context or ""  # <--- æ³¨å…¥ç‚¹
            }
            final_plan = base_plan
            # final_plan = self._expand_plan_with_dependencies(base_plan, context=expansion_context)
            
            self.logger.info(f"Final plan generated with {len(final_plan)} steps (expanded from {len(base_plan)}).")
            return final_plan

        except Exception as e:
            self.logger.error(f"Planning error: {e}", exc_info=True)
            return []



    def shutdown(self) -> None:
        """é‡Šæ”¾èµ„æºï¼Œé‡ç½®çŠ¶æ€"""
        self.tree_manager = None
        self._llm = None
        self._structure_repo = None
        logger.info("[CommonTaskPlanner] Shutdown completed")
    # =========================================================================
    # Phase 1: è¯­ä¹‰æ‹†è§£ (åŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼Œæ”¹åä¸º internal method)
    # =========================================================================

    def _semantic_decomposition(self, agent_id: str, user_input: str, memory_context: str) -> List[Dict]:
        candidates = self._get_candidate_agents_info(agent_id)
        candidate_ids = {item.get("id") for item in candidates if item.get("id")}
        if not candidate_ids:
            return [
                {
                    "step": 1,
                    "type": "AGENT",
                    "executor": agent_id,
                    "content": user_input,
                    "description": "auto_fallback",
                }
            ]
        
        # æ„å»ºå¢å¼ºç‰ˆ Prompt
        prompt = self._build_enhanced_planning_prompt(user_input, memory_context, candidates)
        
        response = self._call_llm(prompt)
        plans = self._parse_llm_json(response)
        for plan in plans:
            if str(plan.get("type", "")).upper() == "AGENT":
                if plan.get("executor") not in candidate_ids:
                    plan["executor"] = agent_id
                    plan["description"] = plan.get("description") or "auto_fallback"
        self.logger.info(f"[CommonTaskPlanner] LLM response:\n{plans}")
        return plans


    def _build_enhanced_planning_prompt(self, user_input, memory, agents):
        agents_str = json.dumps(agents, ensure_ascii=False, indent=2)
        logger.info(f"[CommonTaskPlanner] agents:\n{agents_str}")
        memory_section = ""
        if memory:
            memory_section = f"""
### ğŸ§  é•¿æœŸè®°å¿†ä¸ç”¨æˆ·åå¥½
{memory}
*(è¯·åˆ©ç”¨ä¸Šè¿°è®°å¿†æ¥ä¼˜åŒ–å†³ç­–ã€‚ä¾‹å¦‚ï¼šå¦‚æœè®°å¿†æ˜¾ç¤ºç”¨æˆ·åå¥½"é’‰é’‰"ï¼Œåœ¨é‡åˆ°é€šçŸ¥ç±»ä»»åŠ¡æ—¶è¯·ä¼˜å…ˆé€‰æ‹©ç›¸å…³ MCP å·¥å…·ï¼Œæˆ–åœ¨ params ä¸­å¤‡æ³¨)*
"""

        return (
            f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡ç¼–æ’ä¸“å®¶ã€‚è¯·ç»“åˆã€ç”¨æˆ·æŒ‡ä»¤ã€‘å’Œã€é•¿æœŸè®°å¿†ã€‘åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚

### ğŸ¤– å¯ç”¨å†…éƒ¨èŠ‚ç‚¹ (Agents)
{agents_str}

### ğŸ“¥ ç”¨æˆ·æŒ‡ä»¤
"{user_input}"

### ğŸ“‹ è§„åˆ’è¦æ±‚
1. **è®°å¿†å¢å¼º**ï¼šå¦‚æœç”¨æˆ·æŒ‡ä»¤æ¨¡ç³Šï¼ˆå¦‚"è€æ ·å­"ã€"å‘ç»™é‚£ä¸ªäºº"ï¼‰ï¼Œè¯·æ ¹æ®ã€é•¿æœŸè®°å¿†ã€‘æ¨æ–­å…·ä½“å‚æ•°ï¼Œå¹¶å†™å…¥ `content`ã€‚
2. **èŠ‚ç‚¹é€‰æ‹©**ï¼š
   - è‹¥ä»»åŠ¡å¯ç”±å†…éƒ¨ Agent å®Œæˆï¼ˆå¦‚å†™ä½œã€åˆ†æã€è§„åˆ’ï¼‰ï¼Œé€‰ `"type": "AGENT"`ï¼›
   - è‹¥éœ€è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼ˆå¦‚é’‰é’‰ã€é‚®ä»¶ã€æ•°æ®åº“ï¼‰ï¼Œé€‰ `"type": "MCP"`ã€‚
3. **å­—æ®µå®šä¹‰**ï¼š
   - `content`ï¼š**é¢å‘æ‰§è¡Œ Agent çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤**ï¼Œåº”å®Œæ•´ã€è‡ªåŒ…å«ï¼Œæ— éœ€é¢å¤–ä¸Šä¸‹æ–‡å³å¯ç†è§£ã€‚
   - `description`ï¼š**é¢å‘ç³»ç»Ÿçš„ç®€æ´ä»»åŠ¡æ‘˜è¦**ï¼Œè¯´æ˜â€œåšä»€ä¹ˆâ€ï¼Œä¸åŒ…å«ç»†èŠ‚æˆ–å¼•ç”¨ã€‚
4. **è¾“å‡ºæ ¼å¼**ï¼šçº¯ JSON åˆ—è¡¨ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡æœ¬ã€‚

### âœ… ç¤ºä¾‹è¾“å‡º
[
  {{
    "step": 1,
    "type": "AGENT",
    "executor": "doc_writer",
    "content": "æ ¹æ®ç”¨æˆ·å†å²åå¥½ï¼Œæ’°å†™ä¸€ä»½å…³äºæ–°åŠŸèƒ½çš„ Markdown æ ¼å¼ç”¨æˆ·æ–‡æ¡£ã€‚",
    "description": "ç”Ÿæˆç”¨æˆ·æ–‡æ¡£"
  }},
  {{
    "step": 2,
    "type": "MCP",
    "executor": "dingtalk_bot",
    "content": "å°†ä¸Šä¸€æ­¥ç”Ÿæˆçš„ Markdown æ–‡æ¡£é€šè¿‡é’‰é’‰å‘é€ç»™å°å¼ ï¼ˆç”¨æˆ·å¸¸è”ç³»äººï¼‰ã€‚",
    "description": "é’‰é’‰é€šçŸ¥"
  }}
]
"""
        )
    # =========================================================================
    # Phase 2: ç»“æ„åŒ–ä¾èµ–æ‰©å…… (ä½ æä¾›çš„ SCC é€»è¾‘é›†æˆäºæ­¤)
    # =========================================================================

    def _expand_plan_with_dependencies(self, base_plan: List[Dict], context: Dict) -> List[Dict]:
        """
        æŒ‰åŸå§‹æ­¥éª¤é¡ºåºå¤„ç†ï¼š
        - MCPï¼šåŸä½ä¿ç•™ï¼›
        - AGENTï¼šç”¨å…¶**æœªå±•å¼€è¿‡çš„ä¾èµ–å­å›¾ï¼ˆæŒ‰å…¨å±€æ‹“æ‰‘åºï¼‰** æ›¿æ¢è‡ªèº«ï¼›
        å…¨å±€å»é‡ï¼Œç¡®ä¿æ¯ä¸ª Agent èŠ‚ç‚¹åªæ‰§è¡Œä¸€æ¬¡ã€‚
        """
        if not base_plan:
            return []

        # Step 1: æå–æ‰€æœ‰å”¯ä¸€ AGENT executors
        all_agent_executors = set()
        for step in base_plan:
            if step.get("type") == "AGENT":
                all_agent_executors.add(step["executor"])

        # Step 2: è·å–è”åˆå­å›¾ï¼ˆå« scc_idï¼‰
        all_nodes, all_edges = [], []
        node_to_original_step = {}

        if all_agent_executors:
            result = self._structure_repo.get_influenced_subgraph_with_scc_multi_roots(
                root_codes=list(all_agent_executors),
                threshold=context.get("influence_threshold", 0.3),
                max_hops=5
            )
            all_nodes = result.get("nodes", [])
            all_edges = result.get("edges", [])

            # å»ºç«‹åŸå§‹å…ƒä¿¡æ¯æ˜ å°„ï¼ˆé¦–æ¬¡å‡ºç°ä¸ºå‡†ï¼‰
            for step in base_plan:
                if step.get("type") == "AGENT":
                    eid = step["executor"]
                    if eid not in node_to_original_step:
                        node_to_original_step[eid] = step

        # Step 3: æ„å»ºå…¨å±€ä¾èµ–å›¾
        global_dg = nx.DiGraph()
        node_properties = {}

        for node in all_nodes:
            nid = node["node_id"]
            global_dg.add_node(nid)
            node_properties[nid] = node.get("properties", {})

        for edge in all_edges:
            u, v = edge["from"], edge["to"]
            if u != v:
                global_dg.add_edge(u, v)

        # Step 4: å…¨å±€æ‹“æ‰‘æ’åºï¼ˆæ”¯æŒç¯ï¼‰
        try:
            global_order = list(nx.topological_sort(global_dg))
        except nx.NetworkXUnfeasible:
            # ä½¿ç”¨ SCC ç¼©ç‚¹æ’åºï¼ˆå³ä½¿ Neo4j è¿”å›äº† scc_idï¼Œè¿™é‡Œä»ç”¨ networkx ç¡®ä¿ä¸€è‡´ï¼‰
            global_order = self._topo_sort_with_scc(global_dg, {})

        # Step 5: ååŒè§„åˆ’æ‰€æœ‰èŠ‚ç‚¹å‚æ•°
        task_details = {}
        if all_nodes:
            task_details = self._plan_all_nodes_with_context(
                node_ids=global_order,
                node_properties=node_properties,
                context=context,
                original_meta=node_to_original_step
            )

        # Step 6: æŒ‰åŸå§‹é¡ºåºæ„å»ºæœ€ç»ˆè®¡åˆ’
        final_plan = []
        expanded_cache = set()  # å·²åŠ å…¥ plan çš„èŠ‚ç‚¹ ID

        for orig_step in base_plan:
            if orig_step.get("type") == "MCP":
                final_plan.append(orig_step)
            elif orig_step.get("type") == "AGENT":
                executor = orig_step["executor"]

                # å¦‚æœè¯¥ executor æœ¬èº«ä¸åœ¨å›¾ä¸­ï¼ˆå­¤ç«‹èŠ‚ç‚¹ï¼‰ï¼Œåˆ™ç›´æ¥ä¿ç•™
                if executor not in global_dg:
                    final_plan.append(orig_step)
                    expanded_cache.add(executor)
                    continue

                # æ‰¾å‡ºæ‰€æœ‰â€œä» executor å‡ºå‘å¯è¾¾â€çš„èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
                reachable = {executor}
                try:
                    for descendant in nx.descendants(global_dg, executor):
                        reachable.add(descendant)
                except nx.NodeNotFound:
                    pass  # shouldn't happen

                # ä»å…¨å±€æ‹“æ‰‘åºä¸­ç­›é€‰ï¼šå±äº reachable ä¸”æœªå±•å¼€
                to_insert = [
                    nid for nid in global_order
                    if nid in reachable and nid not in expanded_cache
                ]

                if to_insert:
                    expanded_cache.update(to_insert)
                    for nid in to_insert:
                        detail = task_details.get(nid, {})
                        final_plan.append({
                            "type": "AGENT",
                            "executor": nid,
                            "description": detail.get("intent", f"Execute {nid}"),
                            "params": detail.get("parameters", {}),
                            "is_dependency_expanded": True,
                            "original_parent": executor
                        })
                else:
                    # æ‰€æœ‰ä¾èµ–éƒ½å·²æ‰§è¡Œè¿‡ï¼Œè·³è¿‡ï¼ˆæˆ–ä¿ç•™åŸæ­¥éª¤ï¼Ÿï¼‰
                    # é€šå¸¸ä¸ä¼šå‘ç”Ÿï¼Œä½†ä¸ºå®‰å…¨èµ·è§ï¼Œä¿ç•™åŸæ­¥éª¤
                    final_plan.append(orig_step)

        return self._reindex_steps(final_plan)


    def _fetch_combined_subgraph(self, root_agent_ids: set, context: Dict) -> Tuple[List, List]:
        """
        ä¸€æ¬¡æ€§ä» Neo4j è·å–å¤šä¸ªæ ¹èŠ‚ç‚¹çš„è”åˆå½±å“å­å›¾ã€‚
        å‡è®¾ AgentStructureRepository æ”¯æŒå¤šæ ¹æŸ¥è¯¢ã€‚
        """
        if not self._structure_repo:
            return [], []

        try:
            # ä¿®æ”¹ repo æ¥å£ï¼šæ”¯æŒ roots=list
            result = self._structure_repo.get_influenced_subgraph_with_scc_multi_roots(
                root_codes=list(root_agent_ids),
                threshold=context.get("influence_threshold", 0.3),
                max_hops=5
            )
            return result.get("nodes", []), result.get("edges", [])
        except Exception as e:
            self.logger.warning(f"Failed to fetch combined subgraph: {e}")
            return [], []


    def _plan_single_node_with_qwen(self, node: Dict, context: Dict) -> Dict:
        """
        ä½¿ç”¨ Qwen å¯¹å•ä¸ªèŠ‚ç‚¹è¿›è¡Œè§„åˆ’ã€‚
        """
        # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªä¸Qwenäº¤äº’çš„æ–¹æ³•ï¼Œè¿™é‡Œç®€åŒ–è¡¨ç¤º
        response = self._call_llm(
            f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼š{context}, ä¸ºèŠ‚ç‚¹ {node['properties']} è§„åˆ’æ‰§è¡Œå‚æ•°ã€‚",
            node["properties"]
        )
        
        return {
            "intent": response.get("intent", ""),
            "parameters": response.get("params", {}),
        }

    def _qwen_plan_scc_group(
        self,
        scc_id: str,
        nodes: List[Dict],
        influence_map: Dict,
        main_intent: str,
        global_memory: str
    ) -> Dict[str, Dict]:
        """
        ä½¿ç”¨ Qwen ååŒè§„åˆ’ SCC ç»„ã€‚
        """
        # åˆå¹¶æ‰€æœ‰èŠ‚ç‚¹çš„ä¿¡æ¯ï¼Œæ„å»ºååŒæç¤º
        group_info = [node["properties"] for node in nodes]
        prompt = f"å¯¹äºä¸€ç»„ç›¸äº’ä¾èµ–çš„ä»»åŠ¡ï¼ˆSCC ID: {scc_id}ï¼‰ï¼Œå®ƒä»¬çš„å…±åŒç›®æ ‡æ˜¯ '{main_intent}'ã€‚"
        prompt += "è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ä¸ºæ¯ä¸ªä»»åŠ¡è§„åˆ’æ‰§è¡Œå‚æ•°ï¼š\n"
        for info in group_info:
            prompt += f"- {info}\n"

        # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªä¸Qwenäº¤äº’çš„æ–¹æ³•ï¼Œè¿™é‡Œç®€åŒ–è¡¨ç¤º
        response = self._call_llm(prompt, {"influence_map": influence_map, "global_memory": global_memory})
        
        # è§£æå“åº”ï¼Œæ„é€ è¿”å›ç»“æœ
        task_details = {}
        for node in nodes:
            detail = response.get(node["node_id"], {})
            task_details[node["node_id"]] = {
                "intent": detail.get("intent", ""),
                "parameters": detail.get("params", {}),
            }
        
        return task_details

    def _plan_all_nodes_with_context(
        self,
        node_ids: List[str],
        node_properties: Dict[str, Dict],
        context: Dict,
        original_meta: Dict[str, Dict]
    ) -> Dict[str, Dict]:
        """
        å¯¹æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œå‚æ•°è§„åˆ’ï¼Œæ”¯æŒ SCC åˆ†ç»„ååŒã€‚
        """
        if not node_ids:
            return {}

        # Step 1 & 2: æ„å»ºå›¾å’Œåˆ†ç»„
        dg = nx.DiGraph()
        dg.add_nodes_from(node_ids)
        use_dynamic_scc = False
        scc_groups = {}
        node_to_scc = {}

        for nid in node_ids:
            props = node_properties.get(nid, {})
            scc_id = props.get("scc_id")
            if scc_id is None:
                use_dynamic_scc = True
                break
            node_to_scc[nid] = scc_id
            scc_groups.setdefault(scc_id, []).append({"node_id": nid, "properties": props})

        if use_dynamic_scc:
            # åŠ¨æ€è®¡ç®— SCCï¼ˆé€€åŒ–ä¸ºå•ç‚¹ï¼‰
            scc_groups = {}
            for nid in node_ids:
                scc_id = f"SINGLE_{nid}"
                node_to_scc[nid] = scc_id
                scc_groups[scc_id] = [{"node_id": nid, "properties": node_properties.get(nid, {})}]

        # Step 3: è§„åˆ’æ¯ä¸ªç»„
        all_task_details = {}
        main_intent = context.get("main_intent", "")
        global_memory = context.get("global_memory", "")

        for scc_id, group_nodes in scc_groups.items():
            if len(group_nodes) == 1:
                node = group_nodes[0]
                fallback_params = original_meta.get(node["node_id"], {}).get("params", "")
                sub_context = {
                    "main_intent": main_intent,
                    "global_memory": global_memory,
                    "step_params": fallback_params
                }
                detail = self._plan_single_node_with_qwen(node, sub_context)
                all_task_details[node["node_id"]] = detail
            else:
                group_plan = self._qwen_plan_scc_group(
                    scc_id=scc_id,
                    nodes=group_nodes,
                    influence_map={},  # å¯æ‰©å±•ä¼ å…¥
                    main_intent=main_intent,
                    global_memory=global_memory
                )
                all_task_details.update(group_plan)

        # Step 4: æ ¼å¼åŒ–è¾“å‡ºä»¥ç¬¦åˆæŒ‡å®šæ ¼å¼
        formatted_output = []
        step = 1
        for nid in node_ids:
            detail = all_task_details.get(nid, {})
            formatted_output.append({
                "step": step,
                "type": "AGENT",
                "executor": nid,
                "params": detail.get("parameters", ""),
                "description": detail.get("intent", f"Execute {nid}")
            })
            step += 1
        
        return formatted_output


    def _reindex_steps(self, plan: List[Dict]) -> List[Dict]:
        """ç»Ÿä¸€é‡æ’ step å­—æ®µ"""
        for i, step in enumerate(plan):
            step["step"] = i + 1
        return plan

    # =========================================================================
    # ä½ çš„æ ¸å¿ƒé€»è¾‘é›†æˆ: plan_subtasks & SCC Helpers
    # =========================================================================

    def plan_subtasks(self, parent_agent_id: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        è§„åˆ’å­ä»»åŠ¡åºåˆ—ï¼ˆç»“æ„å±‚ä¸»å…¥å£ï¼‰
        """
        # åªè¦èƒ½è¿ä¸Š Neo4j ä¸”æœ‰ LLMï¼Œå°±å°è¯•ååŒè§„åˆ’
        if self._structure_repo and self._llm:
            return self._plan_with_qwen_coordinated_scc(parent_agent_id, context)
        else:
            # é™çº§ï¼šä»…è¿”å›è‡ªå·±
            return [{"node_id": parent_agent_id, "intent_params": {"parameters": context.get('step_params')}}]

    def _plan_with_qwen_coordinated_scc(self, root_code: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        # 1. è·å–å­å›¾ (å¸¦ SCC ID)
        nodes_data, edges_data = self._fetch_subgraph_with_scc_from_neo4j(
            root_code=root_code,
            threshold=context.get("influence_threshold", 0.3)
        )

        if not nodes_data:
            # æ²¡æœ‰æŸ¥åˆ°ä¾èµ–ï¼Œè¿”å›å•èŠ‚ç‚¹
            return [{"node_id": root_code, "intent_params": {"parameters": context.get('step_params')}}]

        # 2. æŒ‰ SCC åˆ†ç»„
        scc_groups = {}
        node_to_scc = {}
        node_properties = {}

        for node in nodes_data:
            nid = node["node_id"]
            props = node.get("properties", {})
            scc_id = props.get("scc_id", f"SCC_SINGLE_{nid}")
            node_properties[nid] = props
            node_to_scc[nid] = scc_id
            scc_groups.setdefault(scc_id, []).append(node)

        # 3. æ„å»ºå½±å“æ˜ å°„
        influence_map = {nid: [] for nid in node_properties}
        for edge in edges_data:
            u, v, w = edge["from"], edge["to"], edge.get("weight", 0.0)
            if u in influence_map: influence_map[u].append({"target": v, "strength": round(w, 3)})
            if v in influence_map: influence_map[v].append({"source": u, "strength": round(w, 3)})

        # 4. ååŒè§„åˆ’æ¯ä¸ª SCC ç»„
        all_task_details = {}
        for scc_id, group_nodes in scc_groups.items():
            if len(group_nodes) == 1:
                # å•ç‚¹è§„åˆ’
                detail = self._plan_single_node_with_qwen(group_nodes[0], context)
                all_task_details[group_nodes[0]["node_id"]] = detail
            else:
                # å¼ºè€¦åˆç»„ååŒè§„åˆ’
                group_plan = self._qwen_plan_scc_group(
                    scc_id=scc_id,
                    nodes=group_nodes,
                    influence_map=influence_map,
                    main_intent=context.get("main_intent", ""),
                    execution_memory=context.get("execution_memory", {})
                )
                all_task_details.update(group_plan)

        # 5. å…¨å±€æ‹“æ‰‘æ’åº (å¤„ç†ç¯)
        dg = nx.DiGraph()
        dg.add_nodes_from(node_properties.keys())
        for e in edges_data:
            dg.add_edge(e["from"], e["to"])
        
        try:
            global_order = list(nx.topological_sort(dg))
        except nx.NetworkXUnfeasible:
            global_order = self._topo_sort_with_scc(dg, node_to_scc)

        # 6. ç»„è£…ç»“æœ
        result = []
        for node_id in global_order:
            if node_id in all_task_details:
                result.append({
                    "node_id": node_id,
                    "intent_params": all_task_details[node_id]
                })
        return result

    def _fetch_subgraph_with_scc_from_neo4j(self, root_code: str, threshold: float = 0.3) -> Tuple[List, List]:
        """è¿æ¥ Neo4j Repository è·å–æ•°æ®"""
        if not self._structure_repo:
            return [], []
        try:
            # å‡è®¾ repo æœ‰æ­¤æ–¹æ³•
            result = self._structure_repo.get_influenced_subgraph_with_scc(
                root_code=root_code, threshold=threshold, max_hops=5
            )
            return result.get("nodes", []), result.get("edges", [])
        except Exception as e:
            self.logger.warning(f"Neo4j fetch failed: {e}")
            return [], []

    def _qwen_plan_scc_group(self, scc_id, nodes, influence_map, context) -> Dict:
        """
        å¯¹å¼ºè€¦åˆç»„ä»¶è¿›è¡ŒååŒè§„åˆ’ã€‚
        åœ¨æ­¤å¤„ï¼Œè®°å¿†çš„ä½œç”¨æ˜¯ï¼šç¡®ä¿æ‰€æœ‰å…³è”èŠ‚ç‚¹çš„å‚æ•°é£æ ¼ä¸€è‡´ä¸”ç¬¦åˆç”¨æˆ·ä¹ æƒ¯ã€‚
        """
        main_intent = context.get("main_intent", "")
        global_memory = context.get("global_memory", "") # <--- è·å–è®°å¿†
        node_ids = [n["node_id"] for n in nodes]

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé«˜çº§ç³»ç»Ÿåè°ƒ AIã€‚æ­£åœ¨ä¸ºä¸€ä¸ªå¼ºè€¦åˆä»»åŠ¡ç»„ï¼ˆSCCï¼‰ç”Ÿæˆæ‰§è¡Œå‚æ•°ã€‚

## ç»„ ID: {scc_id}
## åŒ…å«èŠ‚ç‚¹: {json.dumps(node_ids, ensure_ascii=False)}
## ä¸»ä»»åŠ¡æ„å›¾: "{main_intent}"

## ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†ä¸åå¥½
{global_memory if global_memory else "æ— å¯ç”¨è®°å¿†"}

## ä½ çš„ä»»åŠ¡
ä¸ºç»„å†…æ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆ `intent` å’Œ `parameters`ã€‚
**å…³é”®è¦æ±‚**ï¼š
1. **ä¸€è‡´æ€§**ï¼šç»„å†…èŠ‚ç‚¹çš„å‚æ•°å¿…é¡»äº’ç›¸å…¼å®¹ï¼ˆå¦‚ï¼šæ–‡ä»¶è·¯å¾„ã€ç‰ˆæœ¬å·ï¼‰ã€‚
2. **ä¸ªæ€§åŒ–**ï¼šå¦‚æœã€ä¸Šä¸‹æ–‡è®°å¿†ã€‘ä¸­æåˆ°äº†ç›¸å…³åå¥½ï¼ˆå¦‚ï¼šè¶…æ—¶æ—¶é—´è®¾ç½®ã€é»˜è®¤å®¡æ‰¹äººã€æ—¥å¿—çº§åˆ«ï¼‰ï¼Œè¯·åŠ¡å¿…åº”ç”¨åˆ°å‚æ•°ä¸­ã€‚
3. **é¡ºåºæ‰§è¡Œ**ï¼šå°½é‡æ ¹æ®èŠ‚ç‚¹é—´çš„seqå¤§å°ï¼Œæ’åºæ‰§è¡Œã€‚

## è¾“å‡º (JSON)
{{
    "task_details": {{
        "node_a": {{ "intent": "...", "parameters": {{ ... }} }},
        "node_b": {{ "intent": "...", "parameters": {{ ... }} }}
    }}
}}
"""
        response = self._call_llm(prompt)
        data = self._parse_llm_json(response)
        if isinstance(data, dict) and "task_details" in data:
            return data["task_details"]
        return {n['node_id']: {"intent": "Coordinated Execution", "parameters": {}} for n in nodes}
    
    
    # å•èŠ‚ç‚¹è§„åˆ’ä¹ŸåŒæ ·æ³¨å…¥è®°å¿†
    def _plan_single_node_with_qwen(self, node, context):
        global_memory = context.get("global_memory", "")
        prompt = f"""
ä»»åŠ¡èŠ‚ç‚¹: {node['node_id']}
å½“å‰æ„å›¾: {context.get('main_intent')}
ç”¨æˆ·è®°å¿†: {global_memory}

è¯·ç”Ÿæˆè¯¥èŠ‚ç‚¹çš„æ‰§è¡Œå‚æ•° JSON (intent, parameters)ã€‚å‚è€ƒç”¨æˆ·è®°å¿†ä¸­çš„åå¥½ã€‚
"""
        res = self._call_llm(prompt)
        parsed = self._parse_llm_json(res)
        if isinstance(parsed, dict): return parsed
        return {"intent": f"Execute {node['node_id']}", "parameters": {}}
    

    def _topo_sort_with_scc(self, graph: nx.DiGraph, node_to_scc: Dict = None) -> List[str]:
        """å¤„ç†å«ç¯å›¾çš„æ‹“æ‰‘æ’åº"""
        scc_graph = nx.DiGraph()
        scc_map = {}
        
        # é‡æ–°è®¡ç®— SCCï¼ˆå¿½ç•¥ä¼ å…¥çš„ node_to_sccï¼‰
        for idx, comp in enumerate(nx.strongly_connected_components(graph)):
            scc_id = f"SCC_{idx}"
            for node in comp:
                scc_map[node] = scc_id
            scc_graph.add_node(scc_id)
        
        for u, v in graph.edges():
            if scc_map[u] != scc_map[v]:
                scc_graph.add_edge(scc_map[u], scc_map[v])
        
        try:
            scc_order = list(nx.topological_sort(scc_graph))
        except:
            scc_order = list(scc_graph.nodes)
        
        # å±•å¼€ SCC å†…éƒ¨ï¼ˆé¡ºåºä¸é‡è¦ï¼Œæˆ–å¯æŒ‰å­—æ¯æ’ï¼‰
        reverse_map = {}
        for node, sid in scc_map.items():
            reverse_map.setdefault(sid, []).append(node)
        
        final_order = []
        for sid in scc_order:
            nodes_in_scc = sorted(reverse_map.get(sid, []))  # ç¡®å®šæ€§æ’åº
            final_order.extend(nodes_in_scc)
        return final_order

    # =========================================================================
    # Helpers (å¤ç”¨ä¹‹å‰çš„)
    # =========================================================================
    
    def _get_candidate_agents_info(self, agent_id: str) -> List[Dict]:
        """è·å–å­èŠ‚ç‚¹çš„è¯¦ç»†æè¿°ï¼Œä¾› LLM åˆ¤æ–­è¾¹ç•Œ"""
        if not self.tree_manager:
            return []
        
        children_ids = self.tree_manager.get_children(agent_id)
        info_list = []
        for cid in children_ids:
            meta = self.tree_manager.get_agent_meta(cid)
            if meta:
                info_list.append({
                    "id": cid,
                    "seq":meta.get("seq", 100),
                    "name": meta.get("name", "Unknown"),
                    "capabilities": meta.get("capability", []), # å‡è®¾è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨æˆ–æè¿°å­—ç¬¦ä¸²
                    "description": meta.get("description", "")
                })
        return info_list

    def _build_planning_prompt(self, user_input: str, memory_context: str, agents: List[Dict]) -> str:
        # åºåˆ—åŒ–å¯ç”¨ Agent åˆ—è¡¨
        agents_str = json.dumps(agents, ensure_ascii=False, indent=2)
        mem_str = memory_context if memory_context else "æ— "

        return (
            f"""
ä½ æ˜¯ä¸€ä¸ªé«˜çº§ä»»åŠ¡ç¼–æ’ä¸“å®¶ã€‚è¯·æ ¹æ®ã€ç”¨æˆ·æŒ‡ä»¤ã€‘åˆ¶å®šä¸€ä¸ªåˆ†æ­¥æ‰§è¡Œè®¡åˆ’ã€‚

### å¯ç”¨çš„å†…éƒ¨ Agent èŠ‚ç‚¹ï¼ˆInternal Agentsï¼‰
{agents_str}

### ä»»åŠ¡ä¸Šä¸‹æ–‡
{mem_str}

### ç”¨æˆ·æŒ‡ä»¤
"{user_input}"

### ä½ çš„å·¥ä½œè¦æ±‚
1. **æ‹†è§£ä»»åŠ¡**ï¼šå°†ç”¨æˆ·æŒ‡ä»¤æ‹†è§£ä¸ºé€»è¾‘é¡ºç•…çš„æ­¥éª¤é“¾ã€‚
2. **èƒ½åŠ›åŒ¹é…ï¼ˆå…³é”®ï¼‰**ï¼š
   - å¦‚æœæŸä¸ªæ­¥éª¤çš„ä»»åŠ¡å¯ä»¥é€šè¿‡ä¸Šè¿°ã€å†…éƒ¨ Agent èŠ‚ç‚¹ã€‘å®Œæˆï¼Œè¯·æ ‡è®° `type` ä¸º "AGENT"ï¼Œå¹¶å‡†ç¡®å¡«å…¥ `executor` (å³ agent id)ã€‚
   - å¦‚æœæŸä¸ªæ­¥éª¤çš„ä»»åŠ¡**ä¸åœ¨**ä¸Šè¿° Agent èƒ½åŠ›èŒƒå›´å†…ï¼ˆä¾‹å¦‚å‘é‚®ä»¶ã€æäº¤OAã€æ“ä½œç³»ç»Ÿæ–‡ä»¶ç­‰ï¼‰ï¼Œè¯·æ ‡è®° `type` ä¸º "MCP"ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªå»ºè®®çš„å·¥å…·åç§°ä½œä¸º `executor`ã€‚
3. **å‚æ•°æå–**ï¼šä»æŒ‡ä»¤ä¸­æå–è¯¥æ­¥éª¤éœ€è¦çš„å…³é”®å‚æ•°ã€‚

### è¾“å‡ºæ ¼å¼
è¯·**ä»…**è¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON åˆ—è¡¨ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚æ ¼å¼èŒƒä¾‹å¦‚ä¸‹ï¼š
[
    {{
        "step": 1,
        "description": "åˆ†ææ–‡æ¡£éœ€æ±‚",
        "type": "AGENT",
        "executor": "analyzer_agent",
        "params": "éœ€åˆ†æçš„æ•°æ®..."
    }},
    {{
        "step": 2,
        "description": "å‘é€é‚®ä»¶ç»™æŸäºº",
        "type": "MCP",
        "executor": "email_client",
        "params": "æ”¶ä»¶äºº: xxx"
    }}
]
"""
        )

    def _parse_llm_json(self, text: str) -> List[Dict]:
        """å¥å£®çš„ JSON è§£æå™¨ï¼Œå¤„ç† LLM å¯èƒ½è¿”å›çš„ä»£ç å—æ ‡è®°"""
        if not text:
            return []
        
        # 1. æ¸…æ´—ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®° ```json ... ```
        cleaned_text = re.sub(r'```json\s*', '', text, flags=re.IGNORECASE)
        cleaned_text = re.sub(r'```', '', cleaned_text)
        cleaned_text = cleaned_text.strip()
        
        try:
            data = json.loads(cleaned_text)
            if isinstance(data, list):
                return data
            # å¦‚æœ LLM åŒ…è£¹äº†ä¸€å±‚å­—å…¸
            if isinstance(data, dict) and 'plan' in data:
                return data['plan']
            return []
        except json.JSONDecodeError:
            self.logger.error(f"JSON Parse Error. Raw Text: {text}")
            # å°è¯•ç”¨æ­£åˆ™æå–åˆ—è¡¨éƒ¨åˆ†ï¼ˆå®¹é”™ï¼‰
            match = re.search(r'\[.*\]', cleaned_text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group())
                except:
                    pass
            return []

    def _call_llm(self, prompt: str) -> str:
        """ç»Ÿä¸€è°ƒç”¨ LLM"""
        # 1. å¦‚æœåˆå§‹åŒ–æ—¶æ³¨å…¥äº† clientï¼Œç›´æ¥ç”¨
        if self._llm:
            try:
                # å‡è®¾ _llm ä¹Ÿæ˜¯ ILLMCapability æ¥å£ï¼Œæ”¯æŒ generate(str)
                return self._llm.generate(prompt)
            except Exception:
                pass # å¤±è´¥åˆ™å°è¯•åŠ¨æ€åŠ è½½
        
        # 2. åŠ¨æ€åŠ è½½ (å…œåº•)
        try:
            from ..llm.interface import ILLMCapability
            from ..registry import capability_registry
            llm = capability_registry.get_capability("llm", ILLMCapability)
            if llm:
                return llm.generate(prompt)
        except ImportError:
            self.logger.error("LLM capability not found.")
        
        return ""
